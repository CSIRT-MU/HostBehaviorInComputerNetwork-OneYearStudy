{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stability of the Temporal Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last, we evaluated the stability of the labeling in time. We assign the labels to host from both training and testing datasets using the cutoff setting . We compare the labels of hosts in the training and testing dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import ipaddress\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import calendar\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>133.250.0.0</th>\n",
       "      <th>133.250.0.1</th>\n",
       "      <th>133.250.0.2</th>\n",
       "      <th>133.250.0.3</th>\n",
       "      <th>133.250.0.4</th>\n",
       "      <th>133.250.0.5</th>\n",
       "      <th>133.250.0.6</th>\n",
       "      <th>133.250.0.7</th>\n",
       "      <th>133.250.0.8</th>\n",
       "      <th>133.250.0.9</th>\n",
       "      <th>...</th>\n",
       "      <th>133.250.255.246</th>\n",
       "      <th>133.250.255.247</th>\n",
       "      <th>133.250.255.248</th>\n",
       "      <th>133.250.255.249</th>\n",
       "      <th>133.250.255.250</th>\n",
       "      <th>133.250.255.251</th>\n",
       "      <th>133.250.255.252</th>\n",
       "      <th>133.250.255.253</th>\n",
       "      <th>133.250.255.254</th>\n",
       "      <th>133.250.255.255</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-01 00:00:00+00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 01:00:00+00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 02:00:00+00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 03:00:00+00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 04:00:00+00:00</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 65536 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           133.250.0.0  133.250.0.1  133.250.0.2  133.250.0.3  \\\n",
       "2019-01-01 00:00:00+00:00          NaN          NaN          NaN          NaN   \n",
       "2019-01-01 01:00:00+00:00          NaN          NaN          NaN          NaN   \n",
       "2019-01-01 02:00:00+00:00          NaN          NaN          NaN          NaN   \n",
       "2019-01-01 03:00:00+00:00          NaN          NaN          NaN          NaN   \n",
       "2019-01-01 04:00:00+00:00          NaN          NaN          NaN          NaN   \n",
       "\n",
       "                           133.250.0.4  133.250.0.5  133.250.0.6  133.250.0.7  \\\n",
       "2019-01-01 00:00:00+00:00          NaN          NaN         48.0          NaN   \n",
       "2019-01-01 01:00:00+00:00          NaN          NaN         55.0          NaN   \n",
       "2019-01-01 02:00:00+00:00          NaN          NaN         43.0          NaN   \n",
       "2019-01-01 03:00:00+00:00          NaN          1.0         43.0          NaN   \n",
       "2019-01-01 04:00:00+00:00          NaN          2.0         71.0          NaN   \n",
       "\n",
       "                           133.250.0.8  133.250.0.9  ...  133.250.255.246  \\\n",
       "2019-01-01 00:00:00+00:00          NaN          NaN  ...              NaN   \n",
       "2019-01-01 01:00:00+00:00          NaN          NaN  ...              NaN   \n",
       "2019-01-01 02:00:00+00:00          NaN          NaN  ...              NaN   \n",
       "2019-01-01 03:00:00+00:00          NaN          NaN  ...              NaN   \n",
       "2019-01-01 04:00:00+00:00          NaN          1.0  ...              NaN   \n",
       "\n",
       "                           133.250.255.247  133.250.255.248  133.250.255.249  \\\n",
       "2019-01-01 00:00:00+00:00              NaN              NaN              NaN   \n",
       "2019-01-01 01:00:00+00:00              NaN              NaN              NaN   \n",
       "2019-01-01 02:00:00+00:00              NaN              NaN              NaN   \n",
       "2019-01-01 03:00:00+00:00              NaN              NaN              NaN   \n",
       "2019-01-01 04:00:00+00:00              NaN              NaN              NaN   \n",
       "\n",
       "                           133.250.255.250  133.250.255.251  133.250.255.252  \\\n",
       "2019-01-01 00:00:00+00:00              NaN              NaN              NaN   \n",
       "2019-01-01 01:00:00+00:00              NaN              NaN              NaN   \n",
       "2019-01-01 02:00:00+00:00              NaN              NaN              NaN   \n",
       "2019-01-01 03:00:00+00:00              NaN              NaN              NaN   \n",
       "2019-01-01 04:00:00+00:00              NaN              NaN              NaN   \n",
       "\n",
       "                           133.250.255.253  133.250.255.254  133.250.255.255  \n",
       "2019-01-01 00:00:00+00:00              NaN              NaN              NaN  \n",
       "2019-01-01 01:00:00+00:00              NaN              NaN              NaN  \n",
       "2019-01-01 02:00:00+00:00              NaN              NaN              NaN  \n",
       "2019-01-01 03:00:00+00:00              NaN              NaN              NaN  \n",
       "2019-01-01 04:00:00+00:00              NaN              NaN              NaN  \n",
       "\n",
       "[5 rows x 65536 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = '../dataset/Flows-anon.csv'\n",
    "df = pd.read_csv(file, header=[0], index_col=[0])\n",
    "df.index = pd.to_datetime(df.index)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_start = ['2019-01-01 00:00:00','2019-02-01 00:00:00','2019-03-01 00:00:00','2019-04-01 00:00:00','2019-05-01 00:00:00','2019-06-01 00:00:00','2019-07-01 00:00:00','2019-08-01 00:00:00','2019-09-01 00:00:00','2019-10-01 00:00:00','2019-11-01 00:00:00','2019-12-01 00:00:00']\n",
    "month_end = ['2019-01-30 23:00:00','2019-02-28 23:00:00', '2019-03-31 23:00:00','2019-04-30 23:00:00','2019-05-31 23:00:00','2019-06-30 23:00:00','2019-07-31 23:00:00','2019-08-31 23:00:00', '2019-09-30 23:00:00','2019-10-31 23:00:00', '2019-11-30 23:00:00', '2019-12-31 23:00:00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of missing observations and days with missing observations\n",
    "def list_missing_days(df):\n",
    "    missing_observations = df[df.isnull().all(axis=1)].index\n",
    "    list_of_missing_days = []\n",
    "    for obs in missing_observations:\n",
    "        if obs.round(freq='D') not in list_of_missing_days:\n",
    "            list_of_missing_days.append(obs.round(freq='D'))\n",
    "    return list_of_missing_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def by_day_mean(series):\n",
    "    \"Ignores days, where no communication has been done and do not add them into mean\"\n",
    "    sum = 0\n",
    "    cnt = 0\n",
    "    for i in series:\n",
    "        if i != 0:\n",
    "            sum = sum+i\n",
    "            cnt += 1\n",
    "    if cnt > 0:\n",
    "        avg = sum/cnt\n",
    "    else:\n",
    "        avg = float('nan')\n",
    "    return avg\n",
    "\n",
    "def most_frequent_value(series):\n",
    "    \"Returns the most frequent value in the serie\"\n",
    "    return np.bincount(series).argmax()\n",
    "\n",
    "def label_night_talker_only(row):\n",
    "    if row['day_talker'] == 0 and row['night_talker']==1:\n",
    "        return 1\n",
    "    else: \n",
    "        return 0\n",
    "\n",
    "def label_day_talker_only(row):\n",
    "    if row['day_talker'] == 1 and row['night_talker']==0:\n",
    "        return 1\n",
    "    else: \n",
    "        return 0\n",
    "\n",
    "def label_day_night_talker_unknown(row):\n",
    "    if row['day_talker'] == 0 and row['night_talker']==0:\n",
    "        return 1\n",
    "    else: \n",
    "        return 0\n",
    "\n",
    "    \n",
    "def weighted_label_day_night_talker(series, hours, statistics):\n",
    "    decision = 0\n",
    "    for statistic in statistics:\n",
    "        if series[statistic] >= hours:\n",
    "            decision += 1\n",
    "    if decision >= 3:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def weighted_label_business_weekend_talker(row, hours, days, statistics):\n",
    "    decision = 0\n",
    "    for statistic in statistics:\n",
    "        days_talked_statistics = \"days_talked_\" + statistic\n",
    "        if row[statistic] >= hours and row[days_talked_statistics]>= days:\n",
    "            decision += 1\n",
    "    \n",
    "    if decision >= 3:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def labels_stability(row, characteristics):\n",
    "    if row['train_'+ characteristics] == row['test_'+ characteristics]:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_labels_diurnal(df):\n",
    "    df['hour'] = df.index.hour\n",
    "\n",
    "    day_hours = df[(df['hour'] >= 6) & (df['hour'] < 18)]\n",
    "    night_hours = df[(df['hour'] < 6) | (df['hour'] >= 18)]\n",
    "    day_hours = day_hours.drop('hour',axis=1)\n",
    "    night_hours = night_hours.drop('hour',axis=1)\n",
    "    \n",
    "    list_of_missing_days = list_missing_days(df)\n",
    "    \n",
    "    day_hours_agg = day_hours.resample('D').count()\n",
    "    day_hours_agg = day_hours_agg.drop(list_of_missing_days)\n",
    "    night_hours_agg = night_hours.resample('D').count()\n",
    "    night_hours_agg = night_hours_agg.drop(list_of_missing_days)\n",
    "\n",
    "    ip_characteristics = pd.DataFrame(index=day_hours_agg.columns)\n",
    "    ip_characteristics['day_hours_by_day_mean'] = day_hours_agg.apply(by_day_mean)\n",
    "    ip_characteristics['day_hours_median'] = day_hours_agg.median()\n",
    "    ip_characteristics['day_hours_mean'] = day_hours_agg.mean()\n",
    "    ip_characteristics['day_hours_most_frequent_value'] = day_hours_agg.apply(most_frequent_value)\n",
    "\n",
    "    ip_characteristics['night_hours_by_day_mean'] = night_hours_agg.apply(by_day_mean)\n",
    "    ip_characteristics['night_hours_median'] = night_hours_agg.median()\n",
    "    ip_characteristics['night_hours_mean'] = night_hours_agg.mean()\n",
    "    ip_characteristics['night_hours_most_frequent_value'] = night_hours_agg.apply(most_frequent_value)\n",
    "\n",
    "    statistics_day = ['day_hours_by_day_mean', 'day_hours_mean', 'day_hours_median', 'day_hours_most_frequent_value']\n",
    "    statistics_night = ['night_hours_by_day_mean', 'night_hours_mean', 'night_hours_median', 'night_hours_most_frequent_value']\n",
    "\n",
    "\n",
    "    ip_characteristics['day_talker'] = ip_characteristics.apply(lambda row: weighted_label_day_night_talker(row, 6, statistics_day), axis =1)\n",
    "    ip_characteristics['night_talker'] = ip_characteristics.apply(lambda row: weighted_label_day_night_talker(row, 5, statistics_night), axis =1)\n",
    "\n",
    "\n",
    "    ip_characteristics['day_talker_only'] = ip_characteristics.apply(lambda row: label_day_talker_only(row), axis =1)\n",
    "    ip_characteristics['night_talker_only'] = ip_characteristics.apply(lambda row: label_night_talker_only(row), axis =1)\n",
    "    ip_characteristics['day_night_talker_unknown'] = ip_characteristics.apply(lambda row: label_day_night_talker_unknown(row), axis =1)\n",
    "\n",
    "    return ip_characteristics[['day_talker', 'night_talker']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assing_labels_weekday(df):\n",
    "    \n",
    "    by_day = df.resample('D').count()\n",
    "    by_day_business = by_day[by_day.index.dayofweek<5]\n",
    "    by_day_weekend = by_day[by_day.index.dayofweek>=5]\n",
    "    \n",
    "    replaced_business = by_day_business.replace(0,float('NaN'))\n",
    "    replaced_business = replaced_business.reset_index()\n",
    "    replaced_business['week_number'] = replaced_business['index'].dt.week\n",
    "    #replaced_business = replaced_business.drop([217,128])\n",
    "    replaced_business = replaced_business.groupby(by='week_number').count()\n",
    "\n",
    "    replaced_weekend = by_day_weekend.replace(0,float('NaN'))\n",
    "    replaced_weekend = replaced_weekend.reset_index()\n",
    "    replaced_weekend['week_number'] = replaced_weekend['index'].dt.week\n",
    "    replaced_weekend = replaced_weekend.groupby(by='week_number').count()\n",
    "    \n",
    "    ip_characteristics = pd.DataFrame(index=by_day_business.columns)\n",
    "    ip_characteristics['business_day_by_day_mean'] = by_day_business.apply(by_day_mean)\n",
    "    ip_characteristics['business_day_median'] = by_day_business.median()\n",
    "    ip_characteristics['business_day_mean'] = by_day_business.mean()\n",
    "    ip_characteristics['business_day_most_frequent_value'] = by_day_business.apply(most_frequent_value)\n",
    "\n",
    "\n",
    "    ip_characteristics['weekend_by_day_mean'] = by_day_weekend.apply(by_day_mean)\n",
    "    ip_characteristics['weekend_median'] = by_day_weekend.median()\n",
    "    ip_characteristics['weekend_mean'] = by_day_weekend.mean()\n",
    "    ip_characteristics['weekend_most_frequent_value'] = by_day_weekend.apply(most_frequent_value)\n",
    "\n",
    "    statistics_business = ['business_day_by_day_mean','business_day_median', 'business_day_mean', 'business_day_most_frequent_value']\n",
    "    statistics_weekend = ['weekend_by_day_mean','weekend_median', 'weekend_mean', 'weekend_most_frequent_value']\n",
    "    \n",
    "    \n",
    "    ip_characteristics['days_talked_business_day_by_day_mean'] = replaced_business.apply(by_day_mean)\n",
    "    ip_characteristics['days_talked_business_day_median'] = replaced_business.median()\n",
    "    ip_characteristics['days_talked_business_day_mean'] = replaced_business.mean()\n",
    "    ip_characteristics['days_talked_business_day_most_frequent_value'] = replaced_business.apply(most_frequent_value)\n",
    "\n",
    "\n",
    "    ip_characteristics['days_talked_weekend_by_day_mean'] = replaced_weekend.apply(by_day_mean)\n",
    "    ip_characteristics['days_talked_weekend_median'] = replaced_weekend.median()\n",
    "    ip_characteristics['days_talked_weekend_mean'] = replaced_weekend.mean()\n",
    "    ip_characteristics['days_talked_weekend_most_frequent_value'] = replaced_weekend.apply(most_frequent_value)\n",
    "\n",
    "    statistics_business_days_talked = ['days_talked_business_day_by_day_mean','days_talked_business_day_median', 'days_talked_business_day_mean', 'days_talked_business_day_most_frequent_value']\n",
    "    statistics_weekend_days_talked = ['days_talked_weekend_by_day_mean','days_talked_weekend_median', 'days_talked_weekend_mean', 'days_talked_weekend_most_frequent_value']\n",
    "\n",
    "    ip_characteristics['business_day_talker'] = ip_characteristics.apply(lambda row: weighted_label_business_weekend_talker(row,8,3,statistics_business), axis =1)\n",
    "    ip_characteristics['weekend_talker'] = ip_characteristics.apply(lambda row: weighted_label_business_weekend_talker(row,8,1, statistics_weekend), axis =1)\n",
    "    \n",
    "    return ip_characteristics[['business_day_talker','weekend_talker']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the label stability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Day night pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign diurnal labels to the training and testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "labels_training = assign_labels_diurnal(df[month_start[0]:month_end[5]])\n",
    "labels_testing = assign_labels_diurnal(df[month_start[9]:month_end[10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the results of labeling\n",
    "labels_training = labels_training.add_prefix('train_')\n",
    "labels_testing= labels_testing.add_prefix('test_')\n",
    "result = pd.concat([labels_training, labels_testing], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Labels:  train_day_talker\n",
      "0    54199\n",
      "1    11337\n",
      "Name: train_day_talker, dtype: int64\n",
      "\n",
      "Labels:  train_night_talker\n",
      "0    58522\n",
      "1     7014\n",
      "Name: train_night_talker, dtype: int64\n",
      "\n",
      "Labels:  test_day_talker\n",
      "0    56230\n",
      "1     9306\n",
      "Name: test_day_talker, dtype: int64\n",
      "\n",
      "Labels:  test_night_talker\n",
      "0    59113\n",
      "1     6423\n",
      "Name: test_night_talker, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Print counts of labels\n",
    "for column in result.columns:\n",
    "    print(\"\\nLabels: \", column)\n",
    "    print(result[column].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Night Talker = 1:\n",
      " 1    5556\n",
      "0    1458\n",
      "Name: stability_night, dtype: int64\n",
      "\n",
      "Night Talker = 0:\n",
      " 1    57655\n",
      "0      867\n",
      "Name: stability_night, dtype: int64\n",
      "\n",
      "Day Talker = 1:\n",
      " 1    8488\n",
      "0    2849\n",
      "Name: stability_day, dtype: int64\n",
      "\n",
      "Day Talker = 0:\n",
      " 1    53381\n",
      "0      818\n",
      "Name: stability_day, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the label stability\n",
    "result['stability_night'] = result.apply(lambda row: labels_stability(row,'night_talker') ,axis=1)\n",
    "result['stability_day'] = result.apply(lambda row: labels_stability(row,'day_talker') ,axis=1)\n",
    "\n",
    "print(\"\\nNight Talker = 1:\\n\", result[result['train_night_talker']==1]['stability_night'].value_counts())\n",
    "print(\"\\nNight Talker = 0:\\n\",result[result['train_night_talker']==0]['stability_night'].value_counts())\n",
    "print(\"\\nDay Talker = 1:\\n\",result[result['train_day_talker']==1]['stability_day'].value_counts())\n",
    "print(\"\\nDay Talker = 0:\\n\",result[result['train_day_talker']==0]['stability_day'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.97     54199\n",
      "           1       0.91      0.75      0.82     11337\n",
      "\n",
      "    accuracy                           0.94     65536\n",
      "   macro avg       0.93      0.87      0.89     65536\n",
      "weighted avg       0.94      0.94      0.94     65536\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98     58522\n",
      "           1       0.87      0.79      0.83      7014\n",
      "\n",
      "    accuracy                           0.96     65536\n",
      "   macro avg       0.92      0.89      0.90     65536\n",
      "weighted avg       0.96      0.96      0.96     65536\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import  classification_report\n",
    "print(classification_report(result['train_day_talker'], result['test_day_talker']))\n",
    "print(classification_report(result['train_night_talker'], result['test_night_talker']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Business day/ weekend pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign labels to the training and testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_training = assing_labels_weekday(df[month_start[0]:month_end[5]])\n",
    "labels_testing = assing_labels_weekday(df[month_start[9]:month_end[10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the results of labeling\n",
    "labels_training = labels_training.add_prefix('train_')\n",
    "labels_testing= labels_testing.add_prefix('test_')\n",
    "result = pd.concat([labels_training, labels_testing], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Labels:  train_business_day_talker\n",
      "0    49850\n",
      "1    15686\n",
      "Name: train_business_day_talker, dtype: int64\n",
      "\n",
      "Labels:  train_weekend_talker\n",
      "0    57527\n",
      "1     8009\n",
      "Name: train_weekend_talker, dtype: int64\n",
      "\n",
      "Labels:  test_business_day_talker\n",
      "0    51340\n",
      "1    14196\n",
      "Name: test_business_day_talker, dtype: int64\n",
      "\n",
      "Labels:  test_weekend_talker\n",
      "0    59227\n",
      "1     6309\n",
      "Name: test_weekend_talker, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Print counts of labels\n",
    "for column in result.columns:\n",
    "    print(\"\\nLabels: \", column)\n",
    "    print(result[column].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    11606\n",
      "0     4080\n",
      "Name: stability_business, dtype: int64\n",
      "1    47260\n",
      "0     2590\n",
      "Name: stability_business, dtype: int64\n",
      "1    5391\n",
      "0    2618\n",
      "Name: stability_weekend, dtype: int64\n",
      "1    56609\n",
      "0      918\n",
      "Name: stability_weekend, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the label stability\n",
    "result['stability_business'] = result.apply(lambda row: labels_stability(row,'business_day_talker') ,axis=1)\n",
    "result['stability_weekend'] = result.apply(lambda row: labels_stability(row,'weekend_talker') ,axis=1)\n",
    "\n",
    "print(result[result['train_business_day_talker']==1]['stability_business'].value_counts())\n",
    "print(result[result['train_business_day_talker']==0]['stability_business'].value_counts())\n",
    "print(result[result['train_weekend_talker']==1]['stability_weekend'].value_counts())\n",
    "print(result[result['train_weekend_talker']==0]['stability_weekend'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.93     49850\n",
      "           1       0.82      0.74      0.78     15686\n",
      "\n",
      "    accuracy                           0.90     65536\n",
      "   macro avg       0.87      0.84      0.86     65536\n",
      "weighted avg       0.90      0.90      0.90     65536\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97     57527\n",
      "           1       0.85      0.67      0.75      8009\n",
      "\n",
      "    accuracy                           0.95     65536\n",
      "   macro avg       0.91      0.83      0.86     65536\n",
      "weighted avg       0.94      0.95      0.94     65536\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import  classification_report\n",
    "print(classification_report(result['train_business_day_talker'], result['test_business_day_talker']))\n",
    "print(classification_report(result['train_weekend_talker'], result['test_weekend_talker']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
